{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import time\n",
    "import math\n",
    "from sdv import Metadata\n",
    "from sdv.tabular import GaussianCopula\n",
    "from sdv.constraints import Unique, UniqueCombinations, GreaterThan, Positive, Rounding, ColumnFormula\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags\n",
    "model_type = 'GC' # Options are: CTGAN\n",
    "syn_level = 'strata' # Options are: country, strata or pcd\n",
    "pop_level = 'sample' # Options are: population or sample\n",
    "encoding = 'categorical' # Options are: 'categorical' or 'label_encoding'\n",
    "field_dist = 'gaussian_kde' # Options are: 'gaussian' or 'parametric'\n",
    "\n",
    "if syn_level != 'country':\n",
    "    sampling_pcd = True\n",
    "else:\n",
    "    sampling_pcd = False\n",
    "\n",
    "if pop_level == 'population':\n",
    "    sampling_population = True\n",
    "else:\n",
    "    sampling_population = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read constraints\n",
    "%run ./synthetic_constraints.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of surveys to synthesize\n",
    "n_sim = 100\n",
    "n_mse = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define SDG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_survey(x):\n",
    "\n",
    "    # Read 'original' survey\n",
    "    dat = pyreadr.read_r('./data/midsave/syn_surveys/survey_' + str(x) + '.rds')[None]\n",
    "\n",
    "    \n",
    "    # Align data types\n",
    "    dat = dat.astype({'pid': int,\n",
    "                      \"strata\": str,\n",
    "                      \"H05A_TOTAL_HOMBRES\": int,\n",
    "                      \"H05B_TOTAL_MUJERES\": int,\n",
    "                      \"V09_CANT_DORMITORIOS\": int,\n",
    "                      \"V10_CANT_APOSENTOS\": int,\n",
    "                      \"V19_CANT_LINEAS_CELULAR\": int,\n",
    "                      \"V01B3_RESIDENTES_HABITUALES\": int,\n",
    "                      \"V02B3_CANT_HOGARES\": int,\n",
    "                      \"P00_NUMERO_LINEA\": float,\n",
    "                      \"P03_EDAD\": int\n",
    "                       })\n",
    "    dat['strata'] = dat['strata'].astype(str)\n",
    "    dat['PSUD'] = dat['PSUD'].astype(str)\n",
    "    \n",
    "    # Add a tiny bit of noise to the line number to get a better ordering later\n",
    "    dat['P00_NUMERO_LINEA'] = dat['P00_NUMERO_LINEA'] + np.random.default_rng().normal(0, 0.1, dat.shape[0])\n",
    "\n",
    "    # Exclude mostly ID variables not needed for SDG\n",
    "    dat = dat.loc[:,dat.columns.str.startswith('pid') | \n",
    "                   dat.columns.str.startswith('strata') |  \n",
    "                   dat.columns.str.startswith('ID_PCD') |  \n",
    "                   dat.columns.str.startswith('PSUD') |  \n",
    "                   dat.columns.str.startswith('ID_AE_CONSECU') |  \n",
    "                   dat.columns.str.startswith('ID_VIVIENDA') |  \n",
    "                   dat.columns.str.startswith('ID_HOGAR') |  \n",
    "                   dat.columns.str.startswith('weight') |  \n",
    "                   dat.columns.str.startswith('V') | \n",
    "                   dat.columns.str.startswith('H') | \n",
    "                   dat.columns.str.startswith('P0') | \n",
    "                   dat.columns.str.startswith('P1') | \n",
    "                   dat.columns.str.startswith('P2') | \n",
    "                   dat.columns.str.startswith('P3') | \n",
    "                   dat.columns.str.startswith('P4') | \n",
    "                   dat.columns.str.startswith('NBI')].copy()\n",
    "\n",
    "\n",
    "    # Set up copula model\n",
    "    if(model_type == 'GC'):\n",
    "        model = GaussianCopula(primary_key='pid',\n",
    "                               default_distribution=field_dist,\n",
    "                               constraints=constraints,\n",
    "                               categorical_transformer=encoding\n",
    "                              )\n",
    "\n",
    "\n",
    "    # Run conditional sampling\n",
    "    if (sampling_pcd == True):\n",
    "    \n",
    "        c_syn = pd.DataFrame()\n",
    "\n",
    "        dat_full = dat.copy()\n",
    "\n",
    "        # For every stratum separately\n",
    "        for y in dat_full.strata.unique().tolist():\n",
    "\n",
    "            dat = dat_full[dat_full['strata'] == y].copy()\n",
    "            \n",
    "            model.fit(dat)\n",
    "    \n",
    "            for z in dat.PSUD.unique().tolist():\n",
    "                if (sampling_population == True):\n",
    "                    smpl = model.sample(round(dat[dat['PSUD'] == z].shape[0]*(dat.loc[dat['PSUD'] == z, 'weight'].reset_index(drop = True)[0])*n_mse),\n",
    "                                        conditions = {'PSUD': z},\n",
    "                                        max_retries = 10000).reset_index(drop = True)\n",
    "                    sub_count = list(range(1,n_mse+1))*math.ceil(smpl.shape[0]/n_mse)\n",
    "                    smpl['sub_sample'] = sub_count[0:smpl.shape[0]]\n",
    "                else:\n",
    "                    smpl = model.sample(dat[dat['PSUD'] == z].shape[0]*n_mse,\n",
    "                                        conditions = {'PSUD': z},\n",
    "                                        max_retries = 10000).reset_index(drop = True)\n",
    "                    smpl['sub_sample'] = list(range(1,n_mse+1))*(dat[dat['PSUD'] == z].shape[0])\n",
    "\n",
    "                # Combine to one survey\n",
    "                c_syn = c_syn.append(smpl)   \n",
    "                \n",
    "    else:\n",
    "        model.fit(dat)\n",
    "        \n",
    "        c_syn = pd.DataFrame()\n",
    "\n",
    "        for z in dat.PSUD.unique().tolist():\n",
    "            if (sampling_population == True):\n",
    "                smpl = model.sample(round(dat[dat['PSUD'] == z].shape[0]*(dat.loc[dat['PSUD'] == z, 'weight'].reset_index(drop = True)[0])*n_mse),\n",
    "                                    conditions = {'PSUD': z},\n",
    "                                    max_retries = 10000).reset_index(drop = True)\n",
    "                sub_count = list(range(1,n_mse+1))*math.ceil(smpl.shape[0]/n_mse)\n",
    "                smpl['sub_sample'] = sub_count[0:smpl.shape[0]]\n",
    "            else:\n",
    "                smpl = model.sample(dat[dat['PSUD'] == z].shape[0]*n_mse,\n",
    "                                    conditions = {'PSUD': z},\n",
    "                                    max_retries = 10000).reset_index(drop = True)\n",
    "                smpl['sub_sample'] = list(range(1,n_mse+1))*(dat[dat['PSUD'] == z].shape[0])\n",
    "\n",
    "            # Combine to one survey\n",
    "            c_syn = c_syn.append(smpl)   \n",
    "\n",
    "    c_syn_post = c_syn.copy()\n",
    "\n",
    "    # Re-create previously excluded ID variables\n",
    "    c_syn_post['ID_PCD'] = c_syn_post['PSUD'].str.slice(0, 5)\n",
    "    c_syn_post['strata'] = c_syn_post['PSUD'].str.slice(start = 5)\n",
    "    c_syn_post['hhid'] = c_syn_post['ID_PCD'].astype(str) + c_syn_post['ID_AE_CONSECU'].astype(str) + c_syn_post['ID_VIVIENDA'].astype(str) + c_syn_post['ID_HOGAR'].astype(str)\n",
    "    c_syn_post['hid'] = c_syn_post['ID_PCD'].astype(str) + c_syn_post['ID_AE_CONSECU'].astype(str) + c_syn_post['ID_VIVIENDA'].astype(str)\n",
    "    c_syn_post['ID_PROVINCIA'] = c_syn_post['hhid'].str.slice(0, 1)\n",
    "    c_syn_post['ID_PC'] = c_syn_post['hhid'].str.slice(0, 3)\n",
    "\n",
    "    c_syn_post.shape\n",
    "\n",
    "\n",
    "    # Some post-processing to ensure census logic\n",
    "    c_syn_post['P05B_CODIGO_PC'] = np.where(c_syn_post.P05A_LUGAR_NACIMIENTO == 'En este mismo cantón', c_syn_post.ID_PC, c_syn_post.P05B_CODIGO_PC)\n",
    "\n",
    "    c_syn_post['P08_PUEBLO_INDIGENA'] = np.where(c_syn_post.P07_INDIGENA == 'No', np.nan, c_syn_post.P08_PUEBLO_INDIGENA)\n",
    "    c_syn_post['P09_HABLA_INDIGENA'] = np.where(c_syn_post.P07_INDIGENA == 'No', np.nan, c_syn_post.P09_HABLA_INDIGENA)\n",
    "    c_syn_post['P10_AFRODESCENDIENTE'] = np.where(c_syn_post.P07_INDIGENA == 'Sí', np.nan, c_syn_post.P10_AFRODESCENDIENTE)\n",
    "\n",
    "    c_syn_post['P12H_NINGUNA'] = np.where((c_syn_post.P12A_LIMITACION_VISUAL == 'No') & \n",
    "                                          (c_syn_post.P12B_LIMITACION_OIR == 'No') & \n",
    "                                          (c_syn_post.P12C_LIMITACION_HABLAR == 'No') & \n",
    "                                          (c_syn_post.P12D_LIMITACION_CAMINAR == 'No') & \n",
    "                                          (c_syn_post.P12E_LIMITACION_BRAZOS_MANOS == 'No') & \n",
    "                                          (c_syn_post.P12F_LIMITACION_INTELECTUAL == 'No') & \n",
    "                                          (c_syn_post.P12G_LIMITACION_MENTAL == 'No'), 'Sí (ninguna de las anteriores)', 'No (al menos una discapacidad)')\n",
    "\n",
    "    c_syn_post['P14_TIPO_EDUCACION_CUIDO'] = np.where(c_syn_post.P13_ASISTE_EDUCACION_CUIDO == 'No asiste', np.nan, c_syn_post.P14_TIPO_EDUCACION_CUIDO)\n",
    "\n",
    "    c_syn_post['P17_OBTUVO_TITULO'] = np.where(c_syn_post.P16_ULTIMO_GRADO_APROBADO.isna() == True, np.nan, c_syn_post.P17_OBTUVO_TITULO)\n",
    "\n",
    "    c_syn_post['P19B_CODIGO_RESIDE'] = np.where(c_syn_post.P19A_LUGAR_RESIDE_HACE_5ANOS == 'En este mismo cantón', c_syn_post.ID_PC, c_syn_post.P19B_CODIGO_RESIDE)\n",
    "\n",
    "    c_syn_post['P22_ACTIVIDAD_REALIZADA'] = np.where(c_syn_post.P21_TRABAJO_SEMANA_PASADA == 'Ninguna de las anteriores', c_syn_post.P22_ACTIVIDAD_REALIZADA, np.nan)\n",
    "    c_syn_post['P23_CONDICION_ACTIVIDAD'] = np.where(c_syn_post.P21_TRABAJO_SEMANA_PASADA == 'Ninguna de las anteriores', c_syn_post.P23_CONDICION_ACTIVIDAD, np.nan)\n",
    "\n",
    "    c_syn_post['P29B_CODIGO_UBICACION_TRABAJO'] = np.where((c_syn_post.P29A_UBICACION_TRABAJO == '...dentro o junto a esta vivienda') | (c_syn_post.P29A_UBICACION_TRABAJO == '...en este mismo cantón'), c_syn_post.ID_PC, c_syn_post.P29B_CODIGO_UBICACION_TRABAJO)\n",
    "\n",
    "    c_syn_post['V08A_ESTADO_PAREDES'] = np.where((c_syn_post.V04_MATERIAL_PAREDES == '... material de desecho') & (c_syn_post.V08A_ESTADO_PAREDES == 'Bueno'), 'Regular', c_syn_post.V08A_ESTADO_PAREDES)\n",
    "\n",
    "    c_syn_post['V08B_ESTADO_TECHO'] = np.where((c_syn_post.V05_MATERIAL_TECHO == '... material de desecho') & (c_syn_post.V08B_ESTADO_TECHO == 'Bueno'), 'Regular', c_syn_post.V08B_ESTADO_TECHO)\n",
    "\n",
    "    c_syn_post['V08C_ESTADO_PISO'] = np.where((c_syn_post.V07_MATERIAL_PISO == 'Piso de tierra') & (c_syn_post.V08C_ESTADO_PISO == 'Bueno'), 'Regular', c_syn_post.V08C_ESTADO_PISO)\n",
    "\n",
    "    c_syn_post['V15_COMBUSTIBLE_COCINAR'] = np.where((c_syn_post.V14_PROVENIENCIA_ELECTRICIDAD == 'No hay luz eléctrica') & (c_syn_post.V15_COMBUSTIBLE_COCINAR == '... electricidad'), '... leña o carbón', c_syn_post.V15_COMBUSTIBLE_COCINAR)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Save\n",
    "\n",
    "    c_syn_post.to_pickle('./data/midsave/syn_surveys/syn_survey_' + str(model_type) +'_' + str(pop_level) +'_' + str(syn_level) +'_' + str(field_dist) +'_' + str(encoding) +'_' + str(n_sim) +'_' + str(n_mse) +'_' + str(x) +'.pkl')\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    delta = (end - start)/60\n",
    "\n",
    "    print('Processing', x, 'of', n_sim, 'surveys. Took %.2f minutes to fit and synthesize.' % delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    with mp.Pool(processes=7) as pool:\n",
    "        \n",
    "        pool.map(synthesize_survey, range(1, n_sim + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
